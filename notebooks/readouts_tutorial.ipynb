{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Readouts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the models in this library are constructed around two main components:\n",
    "- **core**: the core aims to (nonlinearly) extract features that are common between neurons. That is, we assume there exist a shared set of features that all neurons use but combine them in their own unique way.\n",
    "- **readout**: once the core extracts the features, then we can predict neural activity by simply linearly combining those features into a single value.\n",
    "\n",
    "By keeping the readout component of the network simple, during training we force most of the computations to be captured by the shared core.\n",
    "\n",
    "While the core is shared among recording sessions, allowing to use more data for the shared representation learning, the  readout network (or networks), are different for each recording session, as each session will contain a different set of unique neurons we want to predict. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from nnfabrik.builder import get_data\n",
    "from nnfabrik.utility.nn_helpers import set_random_seed, get_dims_for_loader_dict\n",
    "from neuralpredictors.utils import get_module_output\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "random_seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = [\n",
    "    '../../data/static21067-10-18-GrayImageNet-94c6ff995dac583098847cfecd43e7b6.zip', \n",
    "    '../../data/static22846-10-16-GrayImageNet-94c6ff995dac583098847cfecd43e7b6.zip'\n",
    "    ]\n",
    "\n",
    "dataset_fn = 'sensorium.datasets.static_loaders'\n",
    "dataset_config = {'paths': filenames,\n",
    "                 'normalize': True,\n",
    "                 'include_behavior': False,\n",
    "                 'include_eye_position': True,\n",
    "                 'batch_size': 32,\n",
    "                 'scale':1,\n",
    "                 'cuda': True if device == 'cuda' else False,\n",
    "                 }\n",
    "\n",
    "dataloaders = get_data(dataset_fn, dataset_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = {\n",
    "    # core args\n",
    "    'input_kern': 9,\n",
    "    'hidden_kern': 7,\n",
    "    'hidden_channels': 64,\n",
    "    'layers': 4,\n",
    "    'depth_separable': True,\n",
    "    'stack': -1,\n",
    "    'gamma_input': 6.3831,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us define a sample core network to use in the rest of the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/neuralpredictors/regularizers.py:153: UserWarning: LaplaceL2 Regularizer is deprecated. Use LaplaceL2norm instead.\n",
      "  warnings.warn(\"LaplaceL2 Regularizer is deprecated. Use LaplaceL2norm instead.\")\n",
      "/usr/local/lib/python3.8/dist-packages/neuralpredictors/layers/cores/conv2d.py:127: UserWarning: The averaged value of regularizer will be used.\n",
      "  warnings.warn(\"The averaged value of regularizer will be used.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from neuralpredictors.layers.cores import Stacked2dCore\n",
    "\n",
    "# We only need the train dataloaders to extract the session keys (could also use test or validation for this)\n",
    "train_dataloaders = dataloaders[\"train\"]\n",
    "\n",
    "# Obtain the named tuple fields from the first entry of the first dataloader in the dictionary\n",
    "example_batch = next(iter(list(train_dataloaders.values())[0]))\n",
    "in_name, out_name = (\n",
    "    list(example_batch.keys())[:2] if isinstance(example_batch, dict) else example_batch._fields[:2]\n",
    ")\n",
    "\n",
    "session_shape_dict = get_dims_for_loader_dict(train_dataloaders)\n",
    "input_channels = [v[in_name][1] for v in session_shape_dict.values()]\n",
    "\n",
    "core_input_channels = (\n",
    "    list(input_channels.values())[0]\n",
    "    if isinstance(input_channels, dict)\n",
    "    else input_channels[0]\n",
    ")\n",
    "\n",
    "set_random_seed(random_seed)\n",
    "\n",
    "core = Stacked2dCore(\n",
    "    input_channels=core_input_channels,\n",
    "    **model_config,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Readout essentials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All readout networks in the package are initialised with two basic arguments, needed to properly initialised the readout learnable parameters:\n",
    "\n",
    "- `in_shape`\n",
    "- `outdims`\n",
    "- `bias`\n",
    "\n",
    "On top of this, if your dataset contains multiple sessions, you will need to use some instantiation of the `MultiReadoutBase` class, which creates multiple readouts for each session. Paralleling each individual readout instantiation, the multiple readouts takes as arguments:\n",
    "- `in_shape_dict`, which will feed into each single readout `in_shape`\n",
    "- `n_neurons_dict`, which will feed into each single readout `outdims`\n",
    "\n",
    "The keys of both these dictionaries will be the session names, which are also passed in the forward method of this class to choose which individual readout will take care of the forward pass.\n",
    "\n",
    "Let us create these two dictionaries before instantiating our readouts:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_shapes_dict = {\n",
    "    k: get_module_output(core, v[in_name])[1:]\n",
    "    for k, v in session_shape_dict.items()\n",
    "}\n",
    "n_neurons_dict = {k: v[out_name][1] for k, v in session_shape_dict.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Factorised readout\n",
    "\n",
    "https://papers.nips.cc/paper_files/paper/2017/hash/8c249675aea6c3cbd91661bbae767ff1-Abstract.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralpredictors.layers.readouts.factorized import FullFactorized2d\n",
    "from neuralpredictors.layers.readouts.multi_readout import MultiReadoutBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/neuralpredictors/layers/readouts/base.py:88: UserWarning: Readout is NOT initialized with mean activity but with 0!\n",
      "  warnings.warn(\"Readout is NOT initialized with mean activity but with 0!\")\n"
     ]
    }
   ],
   "source": [
    "factorized_readout = MultiReadoutBase(\n",
    "    in_shape_dict=in_shapes_dict,\n",
    "    n_neurons_dict=n_neurons_dict,\n",
    "    base_readout=FullFactorized2d,\n",
    "    bias=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FullFactorized2d (64 x 144 x 256 -> 8372) with bias, normalized"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The multi-readout layer is an instatiation of torch.ModuleDict, \n",
    "# so we can access the individual readouts by their session key\n",
    "\n",
    "factorized_readout[\"21067-10-18\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FullFactorized2d (64 x 144 x 256 -> 8372) with bias, normalized"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factorized_readout[\"21067-10-18\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "factorized_readout[\"21067-10-18\"].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiReadoutBase(\n",
       "  (21067-10-18): FullFactorized2d (64 x 144 x 256 -> 8372) with bias, normalized\n",
       "  (22846-10-16): FullFactorized2d (64 x 144 x 256 -> 7344) with bias, normalized\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factorized_readout "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian readout\n",
    "\n",
    "https://www.biorxiv.org/content/10.1101/2020.10.05.326256v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MultipleFullGaussian2d' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-93767334b3ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m readout = MultipleFullGaussian2d(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0min_shape_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0min_shapes_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_dataloaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mn_neurons_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_neurons_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0minit_mu_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minit_mu_range\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'MultipleFullGaussian2d' is not defined"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
